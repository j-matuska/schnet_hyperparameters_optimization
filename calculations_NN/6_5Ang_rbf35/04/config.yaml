run:
  work_dir: ${hydra:runtime.cwd}
  data_dir: ${run.work_dir}/data
  path: ${run.work_dir}/runs
  experiment: default
  id: ${uuid:1}
  ckpt_path: null
globals:
  model_path: best_model
  cutoff: 5.0
  lr: 0.0001
  property: DS
  aggregation: sum
trainer:
  _target_: pytorch_lightning.Trainer
  devices: 1
  min_epochs: null
  max_epochs: 550
  enable_progress_bar: false
  enable_model_summary: true
  profiler: null
  gradient_clip_val: 0
  accumulate_grad_batches: 1
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  fast_dev_run: false
  overfit_batches: 0
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  limit_test_batches: 1.0
  track_grad_norm: -1
  detect_anomaly: false
  precision: 32
  accelerator: auto
  num_nodes: 1
  tpu_cores: null
  deterministic: false
  inference_mode: false
callbacks:
  model_checkpoint:
    _target_: schnetpack.train.ModelCheckpoint
    monitor: val_loss
    save_top_k: 1
    save_last: true
    mode: min
    verbose: false
    dirpath: checkpoints/
    filename: '{epoch:02d}-{val_loss:.4f}'
    model_path: ${globals.model_path}
    auto_insert_metric_name: true
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: epoch
  early_stopping:
    _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: val_loss
    patience: 200
    mode: min
    min_delta: 0.0
    check_on_train_epoch_end: false
  ema:
    _target_: schnetpack.train.ExponentialMovingAverage
    decay: 0.995
task:
  optimizer_cls: torch.optim.AdamW
  optimizer_args:
    lr: ${globals.lr}
    weight_decay: 0.0
  scheduler_cls: schnetpack.train.ReduceLROnPlateau
  scheduler_monitor: val_loss
  scheduler_args:
    mode: min
    factor: 0.8
    patience: 25
    threshold: 0.0
    threshold_mode: rel
    cooldown: 10
    min_lr: 1.0e-06
    smoothing_factor: 0.0
  _target_: schnetpack.AtomisticTask
  outputs:
  - _target_: schnetpack.task.ModelOutput
    name: ${globals.property}
    loss_fn:
      _target_: torch.nn.MSELoss
    metrics:
      mae:
        _target_: torchmetrics.regression.MeanAbsoluteError
      rmse:
        _target_: torchmetrics.regression.MeanSquaredError
        squared: false
    loss_weight: 1.0
  warmup_steps: 0
model:
  representation:
    radial_basis:
      _target_: schnetpack.nn.radial.GaussianRBF
      n_rbf: 35
      cutoff: ${globals.cutoff}
    _target_: schnetpack.representation.SchNet
    n_atom_basis: 128
    n_interactions: 6
    cutoff_fn:
      _target_: schnetpack.nn.cutoff.CosineCutoff
      cutoff: ${globals.cutoff}
  _target_: schnetpack.model.NeuralNetworkPotential
  input_modules:
  - _target_: schnetpack.atomistic.PairwiseDistances
  output_modules:
  - _target_: schnetpack.atomistic.Atomwise
    output_key: ${globals.property}
    n_in: ${model.representation.n_atom_basis}
    aggregation_mode: ${globals.aggregation}
  postprocessors:
  - _target_: schnetpack.transform.CastTo64
data:
  _target_: schnetpack.data.AtomsDataModule
  datapath: in_vivo04.db
  split_file: split.npz
  batch_size: 10
  num_train: 47906
  num_val: 2995
  num_test: null
  num_workers: 8
  num_val_workers: null
  num_test_workers: null
  transforms:
  - _target_: schnetpack.transform.SubtractCenterOfMass
  - _target_: schnetpack.transform.MatScipyNeighborList
    cutoff: ${globals.cutoff}
  - _target_: schnetpack.transform.CastTo32
logger:
  tensorboard:
    _target_: pytorch_lightning.loggers.tensorboard.TensorBoardLogger
    save_dir: tensorboard/
    name: ''
    default_hp_metric: true
print_config: true
